{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Character-level CNN Model for Gender Classification",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bUtCACjtcEaCwpPLLhWBkhVMYNKGTvyc",
      "authorship_tag": "ABX9TyOFErlCFoZXGR16N3gVVEAG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZhouyaoXie/cnn_gender_prediction_from_first_name/blob/main/Character_level_CNN_Model_for_Gender_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY7eG_KIgDCC"
      },
      "source": [
        "# Character Level CNN Model for Gender Classification\n",
        "\n",
        "Zhouyao Xie\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK7SGjWOWjDu"
      },
      "source": [
        "# 0. Overview\n",
        "\n",
        "The goal is to train a binary classifier that outputs gender predictions given first names as inputs. After some literature research, I was pointed to two papers on character-level convolutional neural nets for text classification ([Zhang, Zhao, Lecun](https://arxiv.org/abs/1509.01626) and [Kim](https://arxiv.org/abs/1408.5882)). First names contain almost no semantic or syntactic information, which makes the task of inferring from first names quite different from understanding normal words. Since not much information is lost from viewing the text at character-level, character-level CNN seems appropriate for the task.\n",
        "\n",
        "The training dataset is the [national name dataset ](https://www.ssa.gov/oact/babynames/limits.html) provided by U.S. Social Security Administration. I used the data from 1950 to 2018, which contains 517490 unique name-gender pairs (including ambiguous names). 2% of the data were randomly sampled to use as the testset. From the rest data, 20% were randomly selected as the validation set.\n",
        "\n",
        "The neural network I implemented below slightly modified Zhang's design. It consists of one 128-filter, three 64-filter 1-D convolution layers, and two fully connected layers. Each convolution layer is followed by a max pooling layer, with pooling size equals to 3. I also used dropout in between the three dense layers to regularize. I used an Adam optimizer with learning rate 0.0005 to perform gradient descent.\n",
        "\n",
        "The model attained an accuracy of **86.11%** on the testset.\n",
        "\n",
        "I also referred to [this](https://github.com/mhjabreel/CharCnn_Keras), [this](https://github.com/Irvinglove/char-CNN-text-classification-tensorflow), and [this](https://github.com/BrambleXu/nlp-beginner-guide-keras/blob/master/char-level-cnn/char_cnn.py) github repos for the implementation of character-level CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aGzwGet4-ds"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, Embedding, Activation\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.layers.core import Dense, Flatten, Dropout\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfqiQZp6lgzm"
      },
      "source": [
        "# I. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgaldIbS5fGd"
      },
      "source": [
        "# import training data\n",
        "gender_ds = pd.DataFrame({})\n",
        "for year in [str(x) for x in range(1950, 2019)]:\n",
        "  gender_ds = gender_ds.append(pd.read_csv('/content/drive/MyDrive/name_gender_classification/yob'+year+'.txt',header=None,names=['name','gender','frequency']))\n",
        "\n",
        "gender_ds.drop_duplicates(inplace = True)\n",
        "\n",
        "# female = gender_ds.loc[gender_ds['gender']=='F'].name.values\n",
        "# male = gender_ds.loc[gender_ds['gender']=='M'].name.values\n",
        "# strictly_female_names = set(female) - set(male)\n",
        "# gender_ds = gender_ds.loc[~gender_ds['name'].isin(list(strictly_female_names)[:len(female) - len(male)])]\n",
        "# print(gender_ds.gender.value_counts())\n",
        "\n",
        "# sample 2% testset\n",
        "test = gender_ds.sample(frac = 0.02)\n",
        "gender_ds = gender_ds.loc[~gender_ds.name.isin(test.name.values)]\n",
        "\n",
        "# train-validate split\n",
        "names_train, names_valid, y_train, y_valid = train_test_split(\n",
        "        gender_ds['name'], gender_ds['gender'], test_size=0.20)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugtFCekDYGEZ",
        "outputId": "61ecfb0c-75f3-4d72-acca-98e1c08feb5e"
      },
      "source": [
        "len(gender_ds)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "517490"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_BX0e3K5jD-"
      },
      "source": [
        "# Preprocessing\n",
        "# lower case all texts\n",
        "names_train = [s.lower() for s in names_train]\n",
        "names_valid = [s.lower() for s in names_valid]\n",
        "\n",
        "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
        "tk.fit_on_texts(names_train)\n",
        "tk.fit_on_texts(names_valid)\n",
        "\n",
        "# Index each letter in the alphabet\n",
        "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "char_dict = {}\n",
        "for i, char in enumerate(alphabet):\n",
        "    char_dict[char] = i + 1\n",
        "tk.word_index = char_dict.copy()\n",
        "\n",
        "# Add 'UNK' to the vocabulary\n",
        "tk.word_index[tk.oov_token] = max(char_dict.values()) + 1\n",
        "\n",
        "# Convert text to sequence of integers\n",
        "train_sequences = tk.texts_to_sequences(names_train)\n",
        "test_texts = tk.texts_to_sequences(names_valid)\n",
        "\n",
        "maxlen = max(gender_ds.name.apply(len))\n",
        "# Apply padding\n",
        "train_data = pad_sequences(train_sequences, maxlen=maxlen, padding='post')\n",
        "test_data = pad_sequences(test_texts, maxlen=maxlen, padding='post')\n",
        "train_data = np.array(train_data, dtype='float32')\n",
        "test_data = np.array(test_data, dtype='float32')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1Ao4lSP5kcQ"
      },
      "source": [
        "# format classes\n",
        "train_class_list = np.where(y_train=='F',0,1)\n",
        "test_class_list = np.where(y_valid=='F',0,1)\n",
        "\n",
        "train_classes = to_categorical(train_class_list)\n",
        "test_classes = to_categorical(test_class_list)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiIPtGGcsr75"
      },
      "source": [
        "# II. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S15W-f7-6z5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43ee24a-9a9a-4a54-9f2f-e8652a7ba9df"
      },
      "source": [
        "# CNN Model\n",
        "# Parameter\n",
        "input_size = np.shape(train_data)[1] #15\n",
        "vocab_size = len(tk.word_index) #27\n",
        "embedding_size = len(tk.word_index) #27\n",
        "conv_layers = [[128, 3, 3],\n",
        "               [64, 3, 3],\n",
        "               [64, 3, 3],\n",
        "               [64, 3, 3]]\n",
        "dense_1 = 128\n",
        "dense_2 = 128\n",
        "num_of_classes = 2\n",
        "dropout_p = 0.5\n",
        "optimizer = optimizers.Adam(lr=.0005)\n",
        "# optimizer = optimizers.SGD(lr=0.001, clipvalue=0.5)\n",
        "# optimizer = optimizers.Adagrad(learning_rate = 0.005)\n",
        "# optimizer = optimizers.Ftrl(learning_rate = 0.001)\n",
        "# optimizer = optimizers.Adamax()\n",
        "\n",
        "loss = 'binary_crossentropy'\n",
        "\n",
        "# # Embedding weights\n",
        "# embedding_weights = []\n",
        "# embedding_weights.append(np.zeros(vocab_size))\n",
        "\n",
        "# # creating one-hot vector for each char\n",
        "# for char, i in tk.word_index.items(): \n",
        "#     onehot = np.zeros(vocab_size)\n",
        "#     onehot[i - 1] = 1\n",
        "#     embedding_weights.append(onehot) #(28,27)\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(vocab_size + 1, #28\n",
        "                            embedding_size, #27\n",
        "                            input_length=input_size,\n",
        "                            embeddings_initializer ='random_normal')\n",
        "# Instantiate keras tensor\n",
        "inputs = Input(shape=(input_size,), \n",
        "               name='input', \n",
        "               dtype='int64')\n",
        "# Embedding\n",
        "x = embedding_layer(inputs)\n",
        "# 1D CNN\n",
        "for filter_num, filter_size, pooling_size in conv_layers:\n",
        "    x = Conv1D(filter_num, filter_size)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling1D(pool_size=pooling_size,data_format='channels_first')(x)\n",
        "x = Flatten()(x)\n",
        "# Fully connected layers\n",
        "x = Dense(dense_1, activation='relu')(x)\n",
        "x = Dropout(dropout_p)(x)\n",
        "x = Dense(dense_2, activation='sigmoid')(x)\n",
        "x = Dropout(dropout_p)(x)\n",
        "# Output Layer\n",
        "predictions = Dense(num_of_classes, activation='sigmoid')(x)\n",
        "# Build model\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# shuffle train and test sets\n",
        "indices = np.arange(train_data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "x_train = train_data[indices]\n",
        "y_train = train_classes[indices]\n",
        "\n",
        "indices = np.arange(test_data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "x_test = test_data[indices]\n",
        "y_test = test_classes[indices]\n",
        "\n",
        "# Train\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_test, y_test),\n",
        "          batch_size=32,\n",
        "          epochs=12,\n",
        "          verbose=2,\n",
        "          #class_weight = {0:0.4, 1:0.6}\n",
        "          )\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 15)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 15, 27)            756       \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 13, 128)           10496     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 13, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 13, 42)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 11, 64)            8128      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 11, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 11, 21)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 9, 64)             4096      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 9, 64)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 9, 21)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 7, 64)             4096      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 7, 64)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 7, 21)             0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 147)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               18944     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 63,286\n",
            "Trainable params: 63,286\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/12\n",
            "12938/12938 - 53s - loss: 0.3541 - accuracy: 0.8501 - val_loss: 0.2968 - val_accuracy: 0.8792\n",
            "Epoch 2/12\n",
            "12938/12938 - 52s - loss: 0.2834 - accuracy: 0.8869 - val_loss: 0.2601 - val_accuracy: 0.8968\n",
            "Epoch 3/12\n",
            "12938/12938 - 52s - loss: 0.2571 - accuracy: 0.8996 - val_loss: 0.2462 - val_accuracy: 0.9036\n",
            "Epoch 4/12\n",
            "12938/12938 - 52s - loss: 0.2407 - accuracy: 0.9065 - val_loss: 0.2392 - val_accuracy: 0.9070\n",
            "Epoch 5/12\n",
            "12938/12938 - 51s - loss: 0.2302 - accuracy: 0.9109 - val_loss: 0.2386 - val_accuracy: 0.9065\n",
            "Epoch 6/12\n",
            "12938/12938 - 51s - loss: 0.2223 - accuracy: 0.9137 - val_loss: 0.2223 - val_accuracy: 0.9120\n",
            "Epoch 7/12\n",
            "12938/12938 - 52s - loss: 0.2160 - accuracy: 0.9164 - val_loss: 0.2174 - val_accuracy: 0.9146\n",
            "Epoch 8/12\n",
            "12938/12938 - 52s - loss: 0.2113 - accuracy: 0.9180 - val_loss: 0.2153 - val_accuracy: 0.9168\n",
            "Epoch 9/12\n",
            "12938/12938 - 51s - loss: 0.2074 - accuracy: 0.9197 - val_loss: 0.2147 - val_accuracy: 0.9175\n",
            "Epoch 10/12\n",
            "12938/12938 - 51s - loss: 0.2044 - accuracy: 0.9209 - val_loss: 0.2081 - val_accuracy: 0.9202\n",
            "Epoch 11/12\n",
            "12938/12938 - 51s - loss: 0.2009 - accuracy: 0.9222 - val_loss: 0.2105 - val_accuracy: 0.9174\n",
            "Epoch 12/12\n",
            "12938/12938 - 51s - loss: 0.1979 - accuracy: 0.9231 - val_loss: 0.2057 - val_accuracy: 0.9220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd15caa0d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW58aaWO8Oba"
      },
      "source": [
        "model.save('/content/drive/MyDrive/name_gender_classification/gender_classifier.h5')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyzzjOuIf9tk"
      },
      "source": [
        "# III. Prepare Testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu5aipAzyEWU"
      },
      "source": [
        "# load model\n",
        "model = keras.models.load_model('/content/drive/MyDrive/name_gender_classification/gender_classifier.h5')\n",
        "\n",
        "# convert an array of first names to the format of NN inputs\n",
        "def get_input_expr(names, tk):\n",
        "  names = [s.lower() for s in names]\n",
        "  sequences = tk.texts_to_sequences(names)\n",
        "  data = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
        "  return np.array(data, dtype='float32')\n",
        "\n",
        "# x_names = get_input_expr(data.name.values)\n",
        "x_names = get_input_expr(test.name.values, tk)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ0phFRItNM4"
      },
      "source": [
        "# IV. Predict and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmx5XInZ-1Nw",
        "outputId": "f816c509-cf43-449b-f368-0f8d74e97cf3"
      },
      "source": [
        "# predict\n",
        "prediction = model.predict(x_names) \n",
        "gender_pred = [str(np.where(x[0]>x[1],'F','M')) for x in prediction]\n",
        "test['pred'] = gender_pred\n",
        "\n",
        "# check accuracy\n",
        "print('Accuracy: ', accuracy_score(test.gender.values, test.pred.values))\n",
        "print('Confusion Matrix: \\n',confusion_matrix(test.gender.values, test.pred.values, labels = ['F', 'M']))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8611001187178472\n",
            "Confusion Matrix: \n",
            " [[9575 1352]\n",
            " [1105 5657]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ7nEa0JmLz9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}